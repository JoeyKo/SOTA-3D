这份 **PRD (v7.1 完善执行版)** 是为你手中的 **RTX 4090** 量身定制的终极开发指南。它剔除了所有冗余的后处理、扩展性思考和复杂架构，只保留实现"图片转 3D 并公网可见"的最核心链路。

---

# ## 3D AI 生成平台 - 完善执行级 PRD

## ### 1. 产品目标

**核心功能**：用户上传一张图片，通过本地 RTX 4090 生成 3D 模型（GLB 格式），并能在全球任何地方通过浏览器直接加载查看。
**交付物**：一个具备生成功能的 Web 页面 + 一个基于本地 GPU 的推理后端。

---

## ### 2. 极简架构图 (Architecture)

1. **前端 (Next.js)**：负责上传图片、显示生成状态、使用 Three.js 渲染模型。
2. **隧道 (Cloudflare)**：负责将本地内网环境安全地暴露到公网。
3. **后端 (FastAPI)**：负责调度 4090 推理、保存文件、提供静态下载链接。

---

## ### 3. 核心功能流程 (Core Workflow)

| 阶段 | 模块 | 执行动作 |
| --- | --- | --- |
| **1. 请求** | 前端 | 通过 HTTP POST 发送图片至公网域名 API 地址。 |
| **2. 推理** | 后端 | 4090 运行 TRELLIS.2 (4B) 采样，生成原始 GLB 数据。 |
| **3. 落地** | 后端 | 将模型以 UUID 命名写入 `./static/` 文件夹（如 `{uuid}.glb`）。 |
| **4. 回传** | 后端 | 返回对应的静态 URL（例如 `https://api.xxx.com/static/{uuid}.glb`）。 |
| **5. 展示** | 前端 | Three.js 直接加载该 URL，执行自动居中显示。 |

---

## ### 4. 关键技术细节 (Technical Specs)

### #### 4.1 后端：算力与分发 (FastAPI)

* **模型状态**：启动即加载（Warm-up），显存占用约 18.5GB。
* **并发控制**：严格限制并发数为 1，使用队列机制处理多请求。
  * 后续请求进入等待队列，按先进先出（FIFO）顺序处理。
  * 队列满（超过 5 个）时，返回 503 状态码提示稍后重试。
* **推理耗时**：单次生成预计 30-90 秒，视模型复杂度而定。
* **超时设置**：后端请求超时设为 180 秒。
* **路径映射**：
```python
app.mount("/static", StaticFiles(directory="static"), name="static")
```

### #### 4.2 网络：内网穿透 (Cloudflare Tunnel)

* **配置**：`cloudflared tunnel run --url http://localhost:8000`。
* **域名**：绑定自定义域名，开启 HTTPS 强制跳转。
* **优势**：无需公网 IP，无需设置路由器转发。
* **注意**：前端必须同样使用 HTTPS 部署，避免 Mixed Content 被浏览器拦截。

### #### 4.3 前端：自适应渲染 (Three.js)

* **加载器**：`GLTFLoader`。
* **自适应逻辑**：
  * 加载模型后计算 `BoundingBox`。
  * 根据 Box 大小自动调整相机位置，确保无论生成模型大小如何，都能在屏幕中心看全。
* **进度反馈**：使用 Server-Sent Events (SSE) 实时推送生成状态：
  * `queued` - 排队中（显示队列位置）
  * `processing` - 推理中（显示进度百分比）
  * `completed` - 生成完成（返回模型 URL）
  * `failed` - 生成失败（返回错误信息）
* **超时设置**：前端请求超时设为 180 秒，超时后提示用户刷新重试。

---

## ### 5. 输入规范 (Input Specs)

| 维度 | 要求 |
| --- | --- |
| **支持格式** | JPG, PNG, WebP |
| **最大文件大小** | 10MB |
| **推荐分辨率** | 512x512 至 2048x2048（更大会自动缩放） |
| **图片内容** | 单一物体、背景简洁效果最佳 |

---

## ### 6. 错误处理 (Error Handling)

| 错误场景 | HTTP 状态码 | 处理方式 |
| --- | --- | --- |
| 图片格式不支持 | 400 | 返回 `{"error": "Unsupported image format"}` |
| 图片过大 | 413 | 返回 `{"error": "File too large, max 10MB"}` |
| 显存不足 | 500 | 自动清理显存并重试一次，仍失败则返回错误 |
| 推理超时 | 504 | 返回 `{"error": "Generation timeout"}` |
| 队列已满 | 503 | 返回 `{"error": "Server busy, retry later"}` |
| 未知错误 | 500 | 记录日志，返回 `{"error": "Internal error"}` |

---

## ### 7. API 接口规范

### POST `/api/generate`

**请求**：
```
Content-Type: multipart/form-data
Body: { image: File }
```

**响应（成功）**：
```json
{
  "success": true,
  "model_url": "https://api.xxx.com/static/{uuid}.glb",
  "generation_time": 45.2
}
```

**响应（失败）**：
```json
{
  "success": false,
  "error": "错误描述"
}
```

### GET `/api/status/{task_id}`

**用途**：SSE 端点，实时推送生成状态。

---

## ### 8. 存储生命周期 (Storage)

* **策略**：物理删除。
* **文件命名**：使用 UUID v4，如 `550e8400-e29b-41d4-a716-446655440000.glb`。
* **实现**：不记录数据库。每天凌晨 3 点运行清理脚本，删除 48 小时前的文件：
```bash
find ./static -name "*.glb" -mmin +2880 -delete
```
* **说明**：使用 `-mmin +2880`（48小时 = 2880分钟）替代 `-mtime +1`，避免刚生成的文件被误删。

---

## ### 9. 部署环境要求

| 维度 | 要求 |
| --- | --- |
| **GPU** | NVIDIA RTX 4090 (24GB VRAM) |
| **OS** | Ubuntu 22.04 LTS |
| **CUDA** | 12.4 |
| **Python** | 3.10+ |
| **网络** | 上行带宽 > 10Mbps (影响外部加载速度) |

---

## ### 10. 监控与日志 (Monitoring)

* **日志记录**：使用 Python `logging` 模块，记录到 `./logs/app.log`。
* **关键日志点**：
  * 请求接收（图片大小、格式）
  * 推理开始/结束（耗时）
  * 错误详情（堆栈跟踪）
* **日志轮转**：每天一个文件，保留 7 天。

---

## ### 11. 执行优先级 (Action Plan)

1. **第一步**：配置 Ubuntu 环境，确保 `nvidia-smi` 能看到 4090。
2. **第二步**：编写 FastAPI 脚本，实现"图片输入 -> 队列处理 -> 文件保存"逻辑。
3. **第三步**：实现 SSE 状态推送端点。
4. **第四步**：启动 `cloudflared` 隧道，确保手机 4G 网络能访问本地 8000 端口。
5. **第五步**：Next.js 调用接口，实现进度显示，并在 Three.js 画布中显示模型。
6. **第六步**：添加错误处理和日志记录。

---

**这份 PRD 是目前最直接、可执行性最强的版本。**

**如果你现在准备动手，我可以为你提供那份整合了"生成、保存、静态路径映射"的 FastAPI 核心 `main.py` 代码。有了它，你只需要安装好环境就能直接跑通整个后端。**